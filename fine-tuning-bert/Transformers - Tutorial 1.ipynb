{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-25T16:55:21.719067Z",
     "start_time": "2020-12-25T16:55:21.713344Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path = []\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "env_packages = '.env/lib/python3.7/site-packages/'\n",
    "\n",
    "sys.path.append(Path(os.getcwd(),env_packages).as_posix())\n",
    "sys.path.append('/home/saraiva/miniconda3/lib/python37.zip')\n",
    "sys.path.append('/home/saraiva/miniconda3/lib/python3.7')\n",
    "sys.path.append('/home/saraiva/miniconda3/lib/python3.7/lib-dynload')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-25T16:56:16.535253Z",
     "start_time": "2020-12-25T16:55:44.949405Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saraiva/Documentos/GitHub/knowledge-acervus/fine-tuning-bert/.env/lib/python3.7/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distilbert-base-uncased-finetuned-sst-2-english\n",
      "label: POSITIVE, with score: 0.9998\n",
      "label: NEGATIVE, with score: 0.5309\n",
      "label: POSITIVE, with score: 0.9968\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "#Carrega classifier padrao\n",
    "classifier = pipeline('sentiment-analysis')\n",
    "print(classifier.model.name_or_path)\n",
    "\n",
    "#Realiza escoragem\n",
    "results = classifier([\"We are very happy to show you the ðŸ¤— Transformers library.\",\n",
    "           \"We hope you don't hate it.\",\n",
    "           'Eu adoro esse produto!!'])\n",
    "\n",
    "for result in results:\n",
    "    print(f\"label: {result['label']}, with score: {round(result['score'], 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-25T17:00:14.956276Z",
     "start_time": "2020-12-25T16:59:50.064258Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nlptown/bert-base-multilingual-uncased-sentiment\n",
      "label: 5 stars, with score: 0.7725\n",
      "label: 5 stars, with score: 0.2365\n",
      "label: 5 stars, with score: 0.7192\n"
     ]
    }
   ],
   "source": [
    "#Carregando um outr classifier de \n",
    "classifier = pipeline('sentiment-analysis',\n",
    "                      model=\"nlptown/bert-base-multilingual-uncased-sentiment\")\n",
    "print(classifier.model.name_or_path)\n",
    "      \n",
    "results = classifier([\"We are very happy to show you the ðŸ¤— Transformers library.\",\n",
    "           \"We hope you don't hate it.\",\n",
    "           'Eu adoro esse produto!!'])\n",
    "\n",
    "for result in results:\n",
    "    print(f\"label: {result['label']}, with score: {round(result['score'], 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-25T17:16:45.860374Z",
     "start_time": "2020-12-25T17:16:35.653398Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 151, 11008, 10115, 112, 162, 11531, 10372, 14381, 12311, 10111, 102, 0, 0, 0, 0, 0], [101, 11312, 25165, 14693, 11157, 58263, 117, 10197, 112, 161, 10297, 15511, 10114, 11923, 10171, 10197, 102], [101, 25577, 11373, 12492, 17483, 106, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "classifier = pipeline('sentiment-analysis', model=model, tokenizer=tokenizer)\n",
    "\n",
    "tokenizer([\"I wouldn't like this potatoe\",\n",
    "           \"We really should love transformers, it's so simple to play with it\",\n",
    "           \"Ah nÃ£o tem problema!\"],padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-25T18:10:56.527582Z",
     "start_time": "2020-12-25T18:10:56.422908Z"
    }
   },
   "outputs": [],
   "source": [
    "if pt_model.name_or_path != \"distilbert-base-uncased-finetuned-sst-2-english\" :\n",
    "    #instancia novo modelo\n",
    "    model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "    pt_model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "inputs = tokenizer([\"We are very happy to show you the ðŸ¤— Transformers library.\",\n",
    "                    \"Whatever dude!\",\n",
    "                    \"Merry Christmas! Love in your life bro.\"],\n",
    "                   padding=True,\n",
    "                   return_token_type_ids=False,\n",
    "                   max_length=512,\n",
    "                   truncation=True,\n",
    "                   return_tensors='pt') #precisamos retornar tensores para inputar no modelo//\n",
    "\n",
    "pt_outputs = pt_model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-25T19:06:49.226579Z",
     "start_time": "2020-12-25T19:06:48.452489Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.2043e-04, 9.9978e-01],\n",
      "        [9.4621e-01, 5.3790e-02],\n",
      "        [1.2783e-04, 9.9987e-01]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([1, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "pt_predictions = F.softmax(pt_outputs[0], dim=-1)\n",
    "\n",
    "#Ultima camada de ativacao antes de softmax\n",
    "print(pt_predictions)\n",
    "\n",
    "#Obtendo predicoes por linha\n",
    "print(pt_predictions.argmax(dim=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DistilBert Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-25T19:02:36.774795Z",
     "start_time": "2020-12-25T19:02:24.818398Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForMaskedLM\n",
    "from transformers import FillMaskPipeline\n",
    "\n",
    "\n",
    "if pt_model.name_or_path != \"distilbert-base-uncased\" :\n",
    "    #instancia novo modelo\n",
    "    model_name = \"distilbert-base-uncased\"\n",
    "    pt_model = AutoModelForMaskedLM.from_pretrained(model_name)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)  \n",
    "    \n",
    "fmp = FillMaskPipeline(model = pt_model,\n",
    "                       tokenizer = tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-25T21:44:13.695405Z",
     "start_time": "2020-12-25T21:44:13.622394Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sequence': '[CLS] the capital of italy is naples! [SEP]',\n",
       "  'score': 0.1677890568971634,\n",
       "  'token': 10553,\n",
       "  'token_str': 'naples'},\n",
       " {'sequence': '[CLS] the capital of italy is milan! [SEP]',\n",
       "  'score': 0.13662037253379822,\n",
       "  'token': 6954,\n",
       "  'token_str': 'milan'},\n",
       " {'sequence': '[CLS] the capital of italy is rome! [SEP]',\n",
       "  'score': 0.13033248484134674,\n",
       "  'token': 4199,\n",
       "  'token_str': 'rome'},\n",
       " {'sequence': '[CLS] the capital of italy is florence! [SEP]',\n",
       "  'score': 0.09330018609762192,\n",
       "  'token': 7701,\n",
       "  'token_str': 'florence'},\n",
       " {'sequence': '[CLS] the capital of italy is turin! [SEP]',\n",
       "  'score': 0.08116588741540909,\n",
       "  'token': 13667,\n",
       "  'token_str': 'turin'}]"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fmp(['The capital of Italy is [MASK]!'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-25T22:05:28.283425Z",
     "start_time": "2020-12-25T22:05:25.681739Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import FeatureExtractionPipeline\n",
    "from transformers import AutoModel\n",
    "\n",
    "def cosine_sim(a,b):\n",
    "    return a.dot(b)/(np.linalg.norm(a)*np.linalg.norm(b))\n",
    "\n",
    "pt_model_fext = AutoModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "feat_ext = FeatureExtractionPipeline(model = pt_model_fext,\n",
    "                          tokenizer = tokenizer)\n",
    "\n",
    "# sent_a = 'The girl next to the exit is really beautiful, her hair shines through the light'\n",
    "# sent_b = 'That woman in the entrance is gorgeous' \n",
    "\n",
    "sent_a = 'That dog is really cute'\n",
    "sent_b = 'I want to play soccer with my friends' \n",
    "\n",
    "result = np.array(feat_ext([sent_a,\n",
    "                            sent_b]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-25T22:05:28.292038Z",
     "start_time": "2020-12-25T22:05:28.284732Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7375967992184406"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_sim(result[0].mean(axis=0),result[1].mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-25T22:05:28.427221Z",
     "start_time": "2020-12-25T22:05:28.294804Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8809934666196906"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_sim(result[0].max(axis=0),result[1].max(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch Learning - Autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-25T17:52:43.991256Z",
     "start_time": "2020-12-25T17:52:43.978754Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.ones(2, 2, requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-25T17:52:44.542263Z",
     "start_time": "2020-12-25T17:52:44.524651Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 3.],\n",
      "        [3., 3.]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y = x + 2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-25T17:52:44.849032Z",
     "start_time": "2020-12-25T17:52:44.827218Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[27., 27.],\n",
      "        [27., 27.]], grad_fn=<MulBackward0>) tensor(27., grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z = y * y * 3\n",
    "out = z.mean()\n",
    "\n",
    "print(z, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-25T17:52:45.837846Z",
     "start_time": "2020-12-25T17:52:45.831946Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.5000, 4.5000],\n",
      "        [4.5000, 4.5000]])\n"
     ]
    }
   ],
   "source": [
    "out.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-25T17:54:23.947321Z",
     "start_time": "2020-12-25T17:54:23.929555Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10., grad_fn=<AddBackward0>)\n",
      "tensor(2.)\n",
      "tensor(3.)\n",
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "x=torch.tensor(3.,requires_grad=True)\n",
    "w=torch.tensor(2.,requires_grad=True)\n",
    "b=torch.tensor(4.,requires_grad=True)\n",
    "\n",
    "y=w*x+b\n",
    "print(y)\n",
    "\n",
    "y.backward()\n",
    "print(x.grad)\n",
    "print(w.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-25T20:29:56.636837Z",
     "start_time": "2020-12-25T20:29:56.626223Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.42857142857142855/(1+0.42857142857142855)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
